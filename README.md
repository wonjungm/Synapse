# Project Synapse (v0.9)

## 팀 (Team)
- **팀명 (Team Name):** Synapse (시냅스)
- **팀원 (Team Members):** 최지희, 문원정, 김현영
- **지도교수 (Advisor):** 심재형 교수님

## 프로젝트 개요 (Project Overview)
본 프로젝트는 대규모 언어 모델(LLM)의 지식 증류 과정에서 발생하는 막대한 연산량과 GPU 자원 활용 비효율 문제를 해결하는 것을 목표로 합니다. 이를 위해 다중 GPU 환경에서의 모델 파티셔닝 및 스케줄링 기법을 탐구하고 구현하여, 연산 부하를 균형 있게 분산시키고 통신 오버헤드를 최소화하는 전략을 개발합니다. 최신 분산 학습 프레임워크와 병렬화 기법을 결합해 지식 증류 파이프라인을 최적화하고, 다양한 GPU 환경에서 효율성과 성능 사이의 최적점을 찾는 연구를 진행합니다.

## 주요 키워드 (Keywords)
`LLM`, `Knowledge Distillation`, `Model Partitioning`, `Multi-GPU Training`, `Scheduling`, `Distributed Optimization`

## 저장소 구조 (Repository Structure)
- `README.md`: 프로젝트의 개요와 목표를 설명합니다.
- `IDEATION.md`: 프로젝트 주제 선정을 위한 아이디어 브레인스토밍 내용을 담습니다.
- `GROUNDRULES.md`: 원활한 협업을 위한 팀 내부 규칙을 정의합니다.

## 버전 정보 (Version)
- 본 파일은 프로젝트의 초기 구상을 담은 Version 0.9 초안입니다.
- This document is a v0.9 draft containing the initial project plan.
